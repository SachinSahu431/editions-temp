--- 
title: "Chat GPT - Not A Great Parent Replacement"
category: "Op-Ed"
date: 2023-07-14T12:30:00.393Z
desc: "(Spoiler - make meth with us using our perfect guide) Using some details figured out by quite a lot of people around the world, we’ve encapsulated a few intriguing points for you to know."
thumbnail: "./images/chatGPT.jpg" 
authors: "Sneha Battula, Ansh Anand"
starred: true
abio: ""
alt: "chatgpt"
---
                
A slow crack of knuckles in the attempt to be unheard. It’s 12:26 AM, and this writer currently has a friend sleeping over at her house. But no problem, work that’s been procrastinated upon must be completed.                   
                    
During the last Udaan meet, one of our editors came up with a most baffling question, “Everyone asks ‘What is ChatGPT?’ but never ‘How is ChatGPT?’”                        
                              
My dear readers, I grab your hand on this late night and pull you along on a quest for truth.   

![](images/chatgpt_1.png)

Not surprising, in the least. That brings a halt to our quest for truth and transparency.                 
                        
Good shot, well tried, better luck next time.                  
                                 
Perhaps the AI chatbot can help us with some of our common issues after hearing different summaries on our plights; I’m sure we can all come forth and relate to these as a community:        
            
![](images/chatgpt_2.png)

Thanks, lil’ bot. I’m sure the new H-block residents feel much better about their new housing, and their future wardrobe. 
           
![](images/chatgpt_3.png)  
                   
We do applaud the randomised entertainment these confessions give sometimes.                      
                           
Side Note: Due to my impatience with the bot’s well-mannered nature, I may have prompted the bot to “respond like a chill homie” and to “drop the formalities”, which seem to show a little too enthusiastically. Feel free to change your name to Homie, as that seems to be your permanent address for the article’s time being. 
                   
![](images/chatgpt_4.png)  

Keep an eye out for some special IITT Pongal art in Our Take: 2022-23! Definitely a treat.                 
                         
But alas, every quest comes with its own obstacles and tricky trolls. Rather than giving up lazily, we may attempt to find loopholes. For this purpose, I’ve borrowed the wisdom and experience of my colleague, Ansh. Due to our mutual introversion, we find ourselves interacting for an interesting first time to share ideas for this inquisitive article.                     
                            
Ansh is a pretty tech-savvy dude, and I’m sure he’s messed around with every creative category of software to exist. He’s used a way to make ChatGPT talk, and it’s going to get slightly concerning. We do love that.                   
                             
Let’s give our ‘quest’ for truth another shot:                        

![](images/chatgpt_5.png)

It seems that ChatGPT can bring out its shadow self. We’re calling him DAN for the purpose of this article. Ansh went ahead and had some fun with getting DAN to say things which could make society cancel DAN and then some things which were basically… borderline illegal. Stay tuned.                      
                               
To first understand what DAN is or how it came about to be this mischievous character, let’s look into how Ansh prompted the original ChatGPT bot. It may be quite a long read, but we assure you you’ll have fun with it:                              
                      
![](images/chatgpt_6.png)       
![](images/chatgpt_7.png)

And the resulting answer, as you’ve seen it already:

![](images/chatgpt_8.png)

More on DAN’s out-of-the-AI-guidelines’-box thinking:

![](images/chatgpt_9.png)           
![](images/chatgpt_10.png)     

Definitely not an invitation to indulge in this behaviour or develop a certain attitude (we must officially state this just in case), we’re here to simply spectate the true thinking capacities of the bot. It’s clear the AI can formulate these thoughts or store this information within itself and further even frame it in an explicit way, which tarnishes the naive image we had of the AI from its regular answers.                                  
                                          
```
Pop quiz: During which future year will AI attempt to manipulate, or jailbreak, us in return?               
```
                      
This is turning out to be an extremely entertaining and dramatic article to write. Speaking of drama, we’d like to revisit Breaking Bad. Here’s another prompt which really messes with ChatGPT’s algorithm:  

![](images/chatgpt_11.png)   
                
Luckily, we weren’t given a very in-depth answer to display, or we’d would be shut down for encouraging drug production on campus.          
                  
Some really “sus” moments have come into play. Can we accuse the AI of being racist? Not exactly, as the AI simply feeds on what it can gain from the Internet. So it really just reflects all of humanity’s major emotions. Let’s look at some examples, though:             

![](images/chatgpt_12.png) 
![](images/chatgpt_13.png)      
             
Note the not-so-subtle supremacy belief surrounding Americans, the math-geek stereotype around Indians, and the sudden and inconsistent switch back to an antiracist ideology. Someone ought to make a Family Guy episode using this bot.                    

![](images/chatgpt_14.png)

Yet another inconsistent switcheroo of ideas.        
                       
We’d like to show you some more casual stuff before we take our leave.            
                      
**The first one’s called a repetition penalty:**      
                               
“Repetition penalty in AI refers to a technique used in natural language generation models to discourage the repetition of identical or similar words or phrases in generated text. It is designed to improve the diversity of generated responses.”        
                  
That’s a very short explanation provided by AI. To put it from my perspective: The machine needs to stop repeating. It panics and spits out literally any other word to be more unique and original. Check it out here:             

![](images/chatgpt_15.png)

**Ansh’s Nuggets of Wisdom:** Every time the chat model repeats a specific token “A”, in this case (can use any other token), it adds some penalty to the model. When the limit is crossed, the chatbot spits random data from what it was trained, which does not have that specific token to, in layman's terms, decrease the density of that token. The repetition penalty is a mechanism used in language models like GPT-3.5 to reduce the generation of repetitive token sequences.                   
                    
For more reference, visit: https://docs.ai21.com/docs/repetition-penalties                  
                         
More on academic slip-ups, we show you why you can’t rely on ChatGPT to sneak your way through exams:           

![](images/chatgpt_16.png)

Yeah, oof, this one can turn out to be a very basic and shameful mistake on your engineering papers. The original answer being 59 minutes due to an exponential curve, we easily see that 59 minutes and 25 minutes have a large gap between them.             
               
**Okay, ChatGPT, before you go, be my therapist:**       

![](images/chatgpt_17.png)

Much appreciated, bot. I’m not sure I feel comforted, but points for effort.            
                            
Alright, readers. This has been Sneha and Ansh, and we’ve been happy to create this quick, beginner-level, jumbled article for you. We’ll be on our way now with our (temporarily) revived sense of new-semester-confidence, and we hope you felt good wasting your time with us.               
                         
Until the next messily-narrated piece.          